{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "ANAD\n",
      "EEKK\n",
      "TESS\n",
      "BAVED\n",
      "SAVEE\n",
      "ShEMO\n",
      "VIVAE\n",
      "CREMA-D\n",
      "RAVDESS\n",
      "CaFE_48k\n",
      "JL corpus\n",
      "URDU-Dataset\n",
      "Acted Emotional Speech Dynamic Database\n",
      "\n",
      "['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "folders = [f for f in sorted(glob('*')) if os.path.isdir(f)]\n",
    "folders.remove('LEGOv2')\n",
    "\n",
    "print(len(folders))\n",
    "for folder in sorted(folders, key=lambda x: len(x)):\n",
    "    print(folder)\n",
    "    \n",
    "emotions = ['anger', 'disgust', \n",
    "            'fear', 'happiness', \n",
    "            'sadness', 'surprise', \n",
    "            'neutral', 'pain']\n",
    "\n",
    "print()\n",
    "\n",
    "print(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANAD FILES 1420\n",
      "ANAD/1sec_segmented_part1/1sec_segmented_part1/V1_1 (1).wav\n",
      "\n",
      "1383\n",
      "MISSING   86\n",
      "FOUND   1334\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "anad_files = sorted(glob('ANAD/*/*/*.wav'))\n",
    "print(f'ANAD FILES {len(anad_files)}')\n",
    "print(anad_files[0])\n",
    "print()\n",
    "\n",
    "file_emotion_dict = dict()\n",
    "\n",
    "with open('./ANAD/ANAD.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i, line in enumerate(reader):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        f, emotion = line[0].strip(\"'\"), line[1]\n",
    "        file_emotion_dict[f] = emotion\n",
    "\n",
    "# from collections import Counter\n",
    "\n",
    "missing_file_list = list()\n",
    "missing = 0\n",
    "found = 0\n",
    "\n",
    "print(len(file_emotion_dict))\n",
    "\n",
    "for f in anad_files:\n",
    "    f_name = os.path.basename(f) \n",
    "    if f_name not in file_emotion_dict:\n",
    "        missing += 1\n",
    "        missing_file_list.append(f_name)\n",
    "#         print(f_name)\n",
    "    else:\n",
    "        found += 1\n",
    "        \n",
    "print(f'MISSING {missing:4}')\n",
    "print(f'FOUND   {found:>4}')\n",
    "\n",
    "# files = [os.path.basename(f) for f in anad_files]\n",
    "\n",
    "# for key in file_emotion_dict:\n",
    "#     if key not in files:\n",
    "#         print(key)\n",
    "\n",
    "# c = Counter([os.path.dirname(f) for f in anad_files])\n",
    "# for e in c.items():\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVEE Meta\n",
      "('SAVEE/AudioData/DC/a01.wav', 'SAVEE_DC', 'anger')\n"
     ]
    }
   ],
   "source": [
    "def get_savee_meta(file):\n",
    "    speaker = 'SAVEE_' + file.split('/')[-2]\n",
    "    pattern_emotion = [('a\\d+.wav', 'anger'),\n",
    "                       ('d\\d+.wav', 'disgust'),\n",
    "                       ('f\\d+.wav', 'fear'),\n",
    "                       ('h\\d+.wav', 'happiness'),\n",
    "                       ('n\\d+.wav', 'neutral'),\n",
    "                       ('sa\\d+.wav', 'sadness'),\n",
    "                       ('su\\d+.wav', 'surprise'),\n",
    "                      ]\n",
    "\n",
    "    f_name = os.path.basename(file)\n",
    "    for pattern, emotion in pattern_emotion:\n",
    "        if re.match(pattern, f_name):\n",
    "            e = emotion\n",
    "            break\n",
    "    return file, speaker, e\n",
    "\n",
    "savee_meta = list(map(get_savee_meta, savee_files))\n",
    "\n",
    "print('SAVEE Meta')\n",
    "print(savee_meta[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESS Meta\n",
      "('TESS/OAF_back_angry.wav', 'TESS_OAF', 'angry')\n"
     ]
    }
   ],
   "source": [
    "def get_tess_meta(file):\n",
    "    f_name = os.path.basename(file)\n",
    "    speaker, word, emotion = f_name.rstrip('.wav').split('_') # YAF_youth_disgust.wav\n",
    "    speaker = f'TESS_{speaker}'\n",
    "    \n",
    "    if emotion == 'ps': emotion = 'surprise'\n",
    "    if emotion == 'sad': emotion = 'sadness'\n",
    "    if emotion == 'happy': emotion = 'happiness'\n",
    "    # anger, disgust, fear, happiness, \n",
    "    # pleasant surprise, sadness, and neutral\n",
    "    return file, speaker, emotion\n",
    "\n",
    "tess_meta = list(map(get_tess_meta, tess_files))\n",
    "\n",
    "print('TESS Meta')\n",
    "print(tess_meta[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAVDESS Meta\n",
      "('RAVDESS/Actor_01/03-01-01-01-01-01-01.wav', 'RAVDESS_01', 'neutral')\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "Vocal channel (01 = speech, 02 = song).\n",
    "Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the ‘neutral’ emotion.\n",
    "Statement (01 = “Kids are talking by the door”, 02 = “Dogs are sitting by the door”).\n",
    "Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
    "'''\n",
    "\n",
    "ravdess_code2emo = {\n",
    " '01': 'neutral', \n",
    " '02': 'calm', \n",
    " '03': 'happiness', \n",
    " '04': 'sadness', \n",
    " '05': 'anger', \n",
    " '06': 'fear', \n",
    " '07': 'disgust', \n",
    " '08': 'surprise'\n",
    "}\n",
    "\n",
    "def get_ravdess_meta(file):\n",
    "    f_name = os.path.basename(file)\n",
    "    mod, _, e, intensity, s, r, actor = f_name.rstrip('.wav').split('-') \n",
    "    # 03-01-01-01-01-02-03.wav\n",
    "    speaker = f'RAVDESS_{actor}'\n",
    "    \n",
    "    emotion = ravdess_code2emo[e]\n",
    "    return file, speaker, emotion\n",
    "\n",
    "ravdess_meta = list(map(get_ravdess_meta, ravdess_files))\n",
    "\n",
    "print('RAVDESS Meta')\n",
    "print(ravdess_meta[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREMA-D Meta\n",
      "('CREMA-D/AudioWAV/1001_DFA_ANG_XX.wav', 'CREMA-D_1001', 'anger')\n"
     ]
    }
   ],
   "source": [
    "crema_d_code2emo = {\n",
    "    'ANG': 'anger',\n",
    "    'DIS': 'disgust',\n",
    "    'FEA': 'fear',\n",
    "    'HAP': 'happiness',\n",
    "    'NEU': 'neutral',\n",
    "    'SAD': 'sadness'\n",
    "}\n",
    "\n",
    "def get_crema_d_meta(file):\n",
    "    f_name = os.path.basename(file)\n",
    "    # 1001_DFA_ANG_XX.wav\n",
    "    actor, s, e, intensity = f_name.rstrip('.wav').split('_') \n",
    "    \n",
    "    speaker = f'CREMA-D_{actor}'\n",
    "    \n",
    "    emotion = crema_d_code2emo[e]\n",
    "    return file, speaker, emotion\n",
    "\n",
    "crema_d_meta = list(map(get_crema_d_meta, crema_d_files))\n",
    "\n",
    "print('CREMA-D Meta')\n",
    "print(crema_d_meta[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URDU Meta\n",
      "('URDU-Dataset/Angry/SM1_F10_A010.wav', 'URDU_SM1', 'anger')\n"
     ]
    }
   ],
   "source": [
    "urdu_code2emo = {\n",
    "    'A': 'anger',\n",
    "    'H': 'happiness',\n",
    "    'N': 'neutral',\n",
    "    'S': 'sadness'\n",
    "}\n",
    "\n",
    "def get_urdu_meta(file):\n",
    "    f_name = os.path.basename(file)\n",
    "    # SM7_F4_H076.wav\n",
    "    actor, _, e = f_name.rstrip('.wav').split('_') \n",
    "    \n",
    "    speaker = f'URDU_{actor}'\n",
    "    \n",
    "    for k in urdu_code2emo:\n",
    "        if k in e:\n",
    "            emotion = urdu_code2emo[k]\n",
    "            break\n",
    "    return file, speaker, emotion\n",
    "\n",
    "urdu_meta = list(map(get_urdu_meta, urdu_files))\n",
    "\n",
    "print('URDU Meta')\n",
    "print(urdu_meta[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAVED Meta\n",
      "('BAVED/0/0-m-21-0-1-105.wav', 'BAVED_0', 'neutral')\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "speaker_id(int) - speaker_gender(m or f) - speaker_age(int) - \n",
    "spoken_word(int from 0 to 6) - spoken_emotion(int from 0 to 2) - \n",
    "record_id(int)\n",
    "'''\n",
    "\n",
    "'''\n",
    "Level 1 is the the standered level, \n",
    "it is the way the speaker speaks daily \n",
    "where he/she is expressing a neutral emotions,\n",
    "finally the level 2 emotion, its when the speaker is expressing \n",
    "a high level of positive or negative emotions \n",
    "(happiness, joy, sadness, anger, etc…\n",
    "'''\n",
    "\n",
    "def get_baved_meta(file):\n",
    "    f_name = os.path.basename(file)\n",
    "    # 0-m-21-1-2-375.wav\n",
    "    actor, g, age, s, e, _ = f_name.rstrip('.wav').split('-') \n",
    "    \n",
    "    speaker = f'BAVED_{actor}'\n",
    "\n",
    "    if e == '0':\n",
    "        emotion = 'sadness'\n",
    "    elif e == '1':\n",
    "        emotion = 'neutral'\n",
    "    elif e == '2':\n",
    "        emotion = \"unknown\"\n",
    "\n",
    "    return file, speaker, emotion\n",
    "\n",
    "baved_meta = list(map(get_baved_meta, baved_files))\n",
    "\n",
    "print('BAVED Meta')\n",
    "print(baved_meta[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIVAE Meta\n",
      "('VIVAE/full_set/S01_achievement_low_01.wav', 'VIVAE_S01', 'sadness')\n"
     ]
    }
   ],
   "source": [
    "def get_vivae_meta(file):\n",
    "    f_name = os.path.basename(file)\n",
    "    # S01_achievement_low_01.wav\n",
    "    actor, e, intensity, _ = f_name.rstrip('.wav').split('_') \n",
    "    \n",
    "    speaker = f'VIVAE_{actor}'\n",
    "\n",
    "    if e == 'achievement':\n",
    "        emotion = 'sadness'\n",
    "    elif e == 'pleasure' or e == 'achievement':\n",
    "        emotion = 'happiness'\n",
    "    else:\n",
    "        emotion = e\n",
    "\n",
    "    return file, speaker, emotion\n",
    "\n",
    "vivae_meta = list(map(get_vivae_meta, vivae_files))\n",
    "\n",
    "print('VIVAE Meta')\n",
    "print(vivae_meta[0])\n",
    "\n",
    "# vivae_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShEMO Meta\n",
      "('ShEMO/female/F01A01.wav', 'ShEMO_F01', 'anger')\n"
     ]
    }
   ],
   "source": [
    "def get_shemo_meta(file):\n",
    "    f_name = os.path.basename(file)\n",
    "    # F03H02.wav\n",
    "    code = f_name.rstrip('.wav') \n",
    "    actor, e, _ = code[0:3],  code[3], code[4:]\n",
    "    \n",
    "    speaker = f'ShEMO_{actor}'\n",
    "    \n",
    "    if e == 'A':\n",
    "        emotion = 'anger'\n",
    "    elif e == 'H':\n",
    "        emotion = 'happiness'\n",
    "    elif e == 'N':\n",
    "        emotion = 'neutral'\n",
    "    elif e == 'S':\n",
    "        emotion = 'sadness'\n",
    "    elif e == 'F':\n",
    "        emotion = 'fear'\n",
    "    elif e == 'W':\n",
    "        emotion = 'surprise'\n",
    "    \n",
    "    return file, speaker, emotion\n",
    "\n",
    "shemo_meta = list(map(get_shemo_meta, shemo_files))\n",
    "\n",
    "print('ShEMO Meta')\n",
    "print(shemo_meta[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File naming rule: \n",
    "# (Gender)(speaker.ID)_(Emotion)_(Sentence.ID)(session.ID)\n",
    "\n",
    "def get_jl_corpus_meta(file):\n",
    "    f_name = os.path.basename(file)\n",
    "    # female1_apologetic_7b_2.wav\n",
    "    actor, e, s, _ = f_name.rstrip('.wav').split('_')\n",
    "\n",
    "    speaker = f'JL_corpus_{actor}'\n",
    "    \n",
    "    # happy, sad, excited, neutral, angry\n",
    "    # encouraging, concerned, assertive, anxious, apologetic\n",
    "    \n",
    "    return file, speaker, emotion\n",
    "\n",
    "jl_corpus_meta = list(map(get_jl_corpus_meta, jl_corpus_files))\n",
    "\n",
    "print('JL corpus Meta')\n",
    "print(jl_corpus_meta[0])\n",
    "\n",
    "# jl_corpus_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CaFE Meta\n",
      "('CaFE_48k/ColŠre/Faible/01-C-1-1.wav', 'CaFE_01', 'anger')\n"
     ]
    }
   ],
   "source": [
    "cafe_code2emo = {\n",
    "    'C': 'anger',\n",
    "    'D': 'disgust',\n",
    "    'J': 'happiness',\n",
    "    'N': 'neutral',\n",
    "    'P': 'fear',\n",
    "    'S': 'surprise',\n",
    "    'T': 'sadness',\n",
    "    \n",
    "}\n",
    "\n",
    "def get_cafe_meta(file):\n",
    "    f_name = os.path.basename(file)\n",
    "    # 01-D-2-1.wav\n",
    "    actor, e, intensity, s = f_name.rstrip('.wav').split('-')\n",
    "\n",
    "    speaker = f'CaFE_{actor}'\n",
    "    \n",
    "    '''\n",
    "    C = Colère\t\t(Anger)\n",
    "    D = Dégoût\t\t(Disgust)\n",
    "    J = Joie\t\t(Happiness)\n",
    "    N = Neutre\t\t(Neutral)\n",
    "    P = Peur\t\t(Fear)\n",
    "    S = Surprise\t(Surprise)\n",
    "    T = Tristesse\t(Sadness)\n",
    "    '''\n",
    "    \n",
    "    emotion = cafe_code2emo[e]\n",
    "    \n",
    "    return file, speaker, emotion\n",
    "\n",
    "cafe_meta = list(map(get_cafe_meta, cafe_files))\n",
    "\n",
    "print('CaFE Meta')\n",
    "print(cafe_meta[0])\n",
    "\n",
    "# cafe_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEKK Meta\n",
      "('EEKK/ekorpus/105.wav', 'EEKK', 'anger')\n"
     ]
    }
   ],
   "source": [
    "import textgrid\n",
    "\n",
    "def get_eekk_meta(file):\n",
    "    tg_file = file.replace('.wav', '.TextGrid')\n",
    "    tg = textgrid.TextGrid.fromFile(tg_file)\n",
    "    speaker = f'EEKK'\n",
    "    \n",
    "    try:\n",
    "        e = tg[4].intervals[0].mark\n",
    "    except IndexError:\n",
    "        e = tg[3].intervals[0].mark\n",
    "    \n",
    "    if e in ['sadness', 'anger', 'neutral', 'joy']:\n",
    "        if e == 'joy': e = 'happiness'\n",
    "        emotion = e\n",
    "    else:\n",
    "        print(tg_file)\n",
    "        emotion = None\n",
    "\n",
    "    return file, speaker, emotion\n",
    "\n",
    "eekk_meta = list(map(get_eekk_meta, eekk_files))\n",
    "\n",
    "print('EEKK Meta')\n",
    "print(eekk_meta[0])\n",
    "\n",
    "# anad_files\n",
    "# eekk_files\n",
    "# aesdd_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AESDD Meta\n",
      "('Acted Emotional Speech Dynamic Database/anger/a01 (1).wav', 'AESDD_1', 'anger')\n"
     ]
    }
   ],
   "source": [
    "aesdd_code2emo = {\n",
    "    'a': 'anger',\n",
    "    'd': 'disgust',\n",
    "    'f': 'fear',\n",
    "    'h': 'happiness',\n",
    "    's': 'sadness'\n",
    "}\n",
    "\n",
    "def get_aesdd_meta(file):\n",
    "    f_name = os.path.basename(file)\n",
    "    # a01 (1).wav\n",
    "    e_s, actor = f_name.rstrip('.wav').split(' ')\n",
    "    e, s = e_s[0], e_s[1:]\n",
    "    actor = actor.strip('(').strip(')')\n",
    "    speaker = f'AESDD_{actor}'\n",
    "    \n",
    "    emotion = aesdd_code2emo[e]\n",
    "    \n",
    "    return file, speaker, emotion\n",
    "\n",
    "aesdd_meta = list(map(get_aesdd_meta, aesdd_files))\n",
    "\n",
    "print('AESDD Meta')\n",
    "print(aesdd_meta[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANAD Meta\n",
      "('ANAD/1sec_segmented_part1/1sec_segmented_part1/V1_1 (1).wav', 'ANAD', 'happy')\n"
     ]
    }
   ],
   "source": [
    "with open('./ANAD/ANAD.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i, line in enumerate(reader):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        f, emotion = line[0].strip(\"'\"), line[1]\n",
    "        file_emotion_dict[f] = emotion\n",
    "\n",
    "def get_anad_meta(file):\n",
    "    f_name = os.path.basename(file)\n",
    "    # a01 (1).wav\n",
    "    try:\n",
    "        e = file_emotion_dict[f_name]\n",
    "        # Happy,angry, and surprised\n",
    "        if e == 'happy': emotion = 'happiness'\n",
    "        elif e == 'angry': emoi\n",
    "    except KeyError:\n",
    "        emotion = None\n",
    "    speaker = 'ANAD'\n",
    "    \n",
    "#     emotion = aesdd_code2emo[e]\n",
    "    \n",
    "    return file, speaker, emotion\n",
    "        \n",
    "anad_meta = list(filter(lambda x: x[2] != None, map(get_anad_meta, anad_files)))\n",
    "\n",
    "print('ANAD Meta')\n",
    "print(anad_meta[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVEE FILES 480\n",
      "SAVEE/AudioData/DC/a01.wav\n",
      "\n",
      "TESS FILES 2800\n",
      "TESS/OAF_back_angry.wav\n",
      "\n",
      "RAVDESS FILES 1440\n",
      "RAVDESS/Actor_01/03-01-01-01-01-01-01.wav\n",
      "\n",
      "CREAMA-D FILES 7442\n",
      "CREMA-D/AudioWAV/1001_DFA_ANG_XX.wav\n",
      "\n",
      "URDU FILES 400\n",
      "URDU-Dataset/Angry/SM1_F10_A010.wav\n",
      "\n",
      "BAVED FILES 1935\n",
      "BAVED/0/0-m-21-0-1-105.wav\n",
      "\n",
      "VIVAE FILES 1085\n",
      "VIVAE/full_set/S01_achievement_low_01.wav\n",
      "\n",
      "ShEMO FILES 3000\n",
      "ShEMO/female/F01A01.wav\n",
      "\n",
      "JL corpus FILES 2400\n",
      "JL corpus/Raw JL corpus (unchecked and unannotated)/JL(wav+txt)/female1_angry_10a_1.wav\n",
      "\n",
      "CaFE FILES 936\n",
      "CaFE_48k/ColŠre/Faible/01-C-1-1.wav\n",
      "\n",
      "ANAD FILES 1420\n",
      "ANAD/1sec_segmented_part1/1sec_segmented_part1/V1_1 (1).wav\n",
      "\n",
      "EEKK FILES 1164\n",
      "EEKK/ekorpus/105.wav\n",
      "\n",
      "AESDD FILES 605\n",
      "Acted Emotional Speech Dynamic Database/anger/a01 (1).wav\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/SuperKogito/SER-datasets\n",
    "\n",
    "# SAVEE\n",
    "# English (British)\n",
    "# SAVEE FILES 480\n",
    "# SAVEE/AudioData/DC/a01.wav\n",
    "# 480 British English utterances by 4 males actors.\n",
    "# 7 emotions: anger, disgust, fear, happiness, sadness, surprise and neutral.\n",
    "savee_files = sorted(glob('SAVEE/AudioData/*/*.wav'))\n",
    "print(f'SAVEE FILES {len(savee_files)}')\n",
    "print(savee_files[0])\n",
    "print()\n",
    "\n",
    "# TESS\n",
    "# English\n",
    "# TESS FILES 2800\n",
    "# TESS/OAF_back_angry.wav\n",
    "# 2800 recording by 2 actresses.\n",
    "# 7 emotions: anger, disgust, fear, happiness, pleasant surprise, sadness, and neutral.\n",
    "tess_files = sorted(glob('TESS/*.wav'))\n",
    "print(f'TESS FILES {len(tess_files)}')\n",
    "print(tess_files[0])\n",
    "print()\n",
    "\n",
    "# RAVDESS\n",
    "# English\n",
    "# 7356 recordings by 24 actors.\n",
    "# Speech file (Audio_Speech_Actors_01-24.zip, 215 MB) contains 1440 files: \n",
    "# 60 trials per actor x 24 actors = 1440.\n",
    "# Song file (Audio_Song_Actors_01-24.zip, 198 MB) contains 1012 files: \n",
    "# 44 trials per actor x 23 actors = 1012.\n",
    "# RAVDESS FILES 1440\n",
    "# RAVDESS/Actor_01/03-01-01-01-01-01-01.wav\n",
    "# 7 emotions: calm, happy, sad, angry, fearful, surprise, and disgust\n",
    "ravdess_files = sorted(glob('RAVDESS/*/*.wav'))\n",
    "print(f'RAVDESS FILES {len(ravdess_files)}')\n",
    "print(ravdess_files[0])\n",
    "print()\n",
    "\n",
    "# CREMA-D\n",
    "# English\n",
    "# 7442 clip of 12 sentences spoken by 91 actors (48 males and 43 females).\n",
    "# CREAMA-D FILES 7442\n",
    "# CREMA-D/AudioWAV/1001_DFA_ANG_XX.wav\n",
    "# 6 emotions: angry, disgusted, fearful, happy, neutral, and sad\n",
    "crema_d_files = sorted(glob('CREMA-D/AudioWAV/*.wav'))\n",
    "print(f'CREAMA-D FILES {len(crema_d_files)}')\n",
    "print(crema_d_files[0])\n",
    "print()\n",
    "\n",
    "# URDU\n",
    "# Urdu\n",
    "# 400 utterances by 38 speakers (27 male and 11 female).\n",
    "# URDU FILES 400\n",
    "# URDU-Dataset/Angry/SM1_F10_A010.wav\n",
    "# 4 emotions: angry, happy, neutral, and sad.\n",
    "urdu_files = sorted(glob('URDU-Dataset/*/*.wav'))\n",
    "print(f'URDU FILES {len(urdu_files)}')\n",
    "print(urdu_files[0])\n",
    "print()\n",
    "\n",
    "# BAVED\n",
    "# Arabic\n",
    "# 1935 recording by 61 speakers (45 male and 16 female).\n",
    "# BAVED FILES 1935\n",
    "# BAVED/0/0-m-21-0-1-105.wav\n",
    "baved_files = sorted(glob('BAVED/*/*.wav'))\n",
    "print(f'BAVED FILES {len(baved_files)}')\n",
    "print(baved_files[0])\n",
    "print()\n",
    "\n",
    "# VIVAE\n",
    "# non-speech, 1085 audio file by ~12 speakers.\n",
    "# VIVAE FILES 1085\n",
    "# VIVAE/full_set/S01_achievement_low_01.wav\n",
    "# non-speech 6 emotions: achievement, anger, fear, pain, pleasure, and surprise \n",
    "# with 3 emotional intensities (low, moderate, strong, peak).\n",
    "vivae_files = sorted(glob('VIVAE/full_set/*.wav'))\n",
    "print(f'VIVAE FILES {len(vivae_files)}')\n",
    "print(vivae_files[0])\n",
    "print()\n",
    "\n",
    "# ShEMO\n",
    "# 3000 semi-natural utterances, equivalent to 3 hours and 25 minutes \n",
    "# of speech data from online radio plays by 87 native-Persian speakers.\n",
    "# ShEMO FILES 3000\n",
    "# ShEMO/female/F01A01.wav\n",
    "# 6 emotions: anger, fear, happiness, sadness, neutral and surprise.\n",
    "shemo_files = sorted(glob('ShEMO/*/*.wav'))\n",
    "print(f'ShEMO FILES {len(shemo_files)}')\n",
    "print(shemo_files[0])\n",
    "print()\n",
    "\n",
    "# JL corpus\n",
    "# 2400 recording of 240 sentences by 4 actors (2 males and 2 females).\n",
    "# JL corpus FILES 2400\n",
    "# ShEMO/female/F01A01.wav\n",
    "# 5 primary emotions: angry, sad, neutral, happy, excited. \n",
    "# 5 secondary emotions: anxious, apologetic, pensive, worried, enthusiastic.\n",
    "jl_corpus_files = sorted(glob('JL corpus/Raw JL corpus (unchecked and unannotated)/JL(wav+txt)/*.wav'))\n",
    "print(f'JL corpus FILES {len(jl_corpus_files)}')\n",
    "print(jl_corpus_files[0])\n",
    "print()\n",
    "\n",
    "# CaFE\n",
    "# French (Canadian)\n",
    "# 6 different sentences by 12 speakers (6 fmelaes + 6 males).\n",
    "# 12 * 6 * (6 * 2 + 1) \n",
    "# CaFE FILES 936\n",
    "# CaFE_48k/ColŠre/Faible/01-C-1-1.wav\n",
    "# 7 emotions: happy, sad, angry, fearful, surprise, disgust and neutral. \n",
    "# Each emotion is acted in 2 different intensities.\n",
    "cafe_files = sorted(glob('CaFE_48k/*/*/*.wav') + glob('CaFE_48k/*/*.wav'))\n",
    "print(f'CaFE FILES {len(cafe_files)}')\n",
    "print(cafe_files[0])\n",
    "print()\n",
    "\n",
    "# ANAD\n",
    "# Arabic\n",
    "# 1384 recording by multiple speakers.\n",
    "# ANAD FILES 1420\n",
    "# ANAD/1sec_segmented_part1/1sec_segmented_part1/V1_1 (1).wav\n",
    "# 3 emotions: angry, happy, surprised.\n",
    "anad_files = sorted(glob('ANAD/*/*/*.wav'))\n",
    "print(f'ANAD FILES {len(anad_files)}')\n",
    "print(anad_files[0])\n",
    "print()\n",
    "\n",
    "# EEKK\n",
    "# Estonian\n",
    "# 26 text passage read by 10 speakers.\n",
    "# EEKK FILES 1164\n",
    "# EEKK/ekorpus/105.wav\n",
    "# 4 main emotions: joy, sadness, anger and neutral.\n",
    "eekk_files = sorted(glob('EEKK/ekorpus/*.wav'))\n",
    "print(f'EEKK FILES {len(eekk_files)}')\n",
    "print(eekk_files[0])\n",
    "print()\n",
    "\n",
    "# AESDD\n",
    "# Greek\n",
    "# around 500 utterances by a diverse group of actors (over 5 actors) simlating various emotions.\n",
    "# AESDD FILES 605\n",
    "# Acted Emotional Speech Dynamic Database/anger/a01 (1).wav\n",
    "# 5 emotions: anger, disgust, fear, happiness, and sadness.\n",
    "aesdd_files = sorted(glob('Acted Emotional Speech Dynamic Database/*/*.wav'))\n",
    "print(f'AESDD FILES {len(aesdd_files)}')\n",
    "print(aesdd_files[0])\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMODB\n",
    "IEMCAO\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
