{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "ANAD\n",
      "EEKK\n",
      "TESS\n",
      "BAVED\n",
      "SAVEE\n",
      "ShEMO\n",
      "VIVAE\n",
      "CREMA-D\n",
      "RAVDESS\n",
      "CaFE_48k\n",
      "JL corpus\n",
      "URDU-Dataset\n",
      "Acted Emotional Speech Dynamic Database\n",
      "\n",
      "['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "folders = [f for f in sorted(glob('*')) if os.path.isdir(f)]\n",
    "folders.remove('LEGOv2')\n",
    "\n",
    "print(len(folders))\n",
    "for folder in sorted(folders, key=lambda x: len(x)):\n",
    "    print(folder)\n",
    "    \n",
    "emotions = ['anger', 'disgust', \n",
    "            'fear', 'happiness', \n",
    "            'sadness', 'surprise', 'neutral']\n",
    "\n",
    "print()\n",
    "\n",
    "print(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANAD FILES 1420\n",
      "ANAD/1sec_segmented_part1/1sec_segmented_part1/V1_1 (1).wav\n",
      "\n",
      "1383\n",
      "MISSING   86\n",
      "FOUND   1334\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "anad_files = sorted(glob('ANAD/*/*/*.wav'))\n",
    "print(f'ANAD FILES {len(anad_files)}')\n",
    "print(anad_files[0])\n",
    "print()\n",
    "\n",
    "file_emotion_dict = dict()\n",
    "\n",
    "with open('./ANAD/ANAD.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i, line in enumerate(reader):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        f, emotion = line[0].strip(\"'\"), line[1]\n",
    "        file_emotion_dict[f] = emotion\n",
    "\n",
    "# from collections import Counter\n",
    "\n",
    "missing_file_list = list()\n",
    "missing = 0\n",
    "found = 0\n",
    "\n",
    "print(len(file_emotion_dict))\n",
    "\n",
    "for f in anad_files:\n",
    "    f_name = os.path.basename(f) \n",
    "    if f_name not in file_emotion_dict:\n",
    "        missing += 1\n",
    "        missing_file_list.append(f_name)\n",
    "#         print(f_name)\n",
    "    else:\n",
    "        found += 1\n",
    "        \n",
    "print(f'MISSING {missing:4}')\n",
    "print(f'FOUND   {found:>4}')\n",
    "\n",
    "# files = [os.path.basename(f) for f in anad_files]\n",
    "\n",
    "# for key in file_emotion_dict:\n",
    "#     if key not in files:\n",
    "#         print(key)\n",
    "\n",
    "# c = Counter([os.path.dirname(f) for f in anad_files])\n",
    "# for e in c.items():\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SAVEE/AudioData/DC/a01.wav', 'SAVEE_DC', 'anger')\n"
     ]
    }
   ],
   "source": [
    "def get_savee_meta(file):\n",
    "    speaker = 'SAVEE_' + file.split('/')[-2]\n",
    "    pattern_emotion = [('a\\d+.wav', 'anger'),\n",
    "                       ('d\\d+.wav', 'disgust'),\n",
    "                       ('f\\d+.wav', 'fear'),\n",
    "                       ('h\\d+.wav', 'happiness'),\n",
    "                       ('n\\d+.wav', 'neutral'),\n",
    "                       ('sa\\d+.wav', 'sadness'),\n",
    "                       ('su\\d+.wav', 'surprise'),\n",
    "                      ]\n",
    "\n",
    "    f_name = os.path.basename(file)\n",
    "    for pattern, emotion in pattern_emotion:\n",
    "        if re.match(pattern, f_name):\n",
    "            e = emotion\n",
    "            break\n",
    "    return file, speaker, e\n",
    "\n",
    "savee_meta = list(map(get_savee_meta, savee_files))\n",
    "\n",
    "print(savee_meta[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tess_meta(file):\n",
    "    \n",
    "    return\n",
    "\n",
    "tess_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVEE FILES 480\n",
      "SAVEE/AudioData/DC/a01.wav\n",
      "\n",
      "TESS FILES 2800\n",
      "TESS/OAF_back_angry.wav\n",
      "\n",
      "RAVDESS FILES 1440\n",
      "RAVDESS/Actor_01/03-01-01-01-01-01-01.wav\n",
      "\n",
      "CREAMA-D FILES 7442\n",
      "CREMA-D/AudioWAV/1001_DFA_ANG_XX.wav\n",
      "\n",
      "URDU FILES 400\n",
      "URDU-Dataset/Angry/SM1_F10_A010.wav\n",
      "\n",
      "BAVED FILES 1935\n",
      "BAVED/0/0-m-21-0-1-105.wav\n",
      "\n",
      "VIVAE FILES 1085\n",
      "VIVAE/full_set/S01_achievement_low_01.wav\n",
      "\n",
      "ShEMO FILES 3000\n",
      "ShEMO/female/F01A01.wav\n",
      "\n",
      "JL corpus FILES 2400\n",
      "ShEMO/female/F01A01.wav\n",
      "\n",
      "CaFE FILES 936\n",
      "CaFE_48k/ColŠre/Faible/01-C-1-1.wav\n",
      "\n",
      "ANAD FILES 1420\n",
      "ANAD/1sec_segmented_part1/1sec_segmented_part1/V1_1 (1).wav\n",
      "\n",
      "EEKK FILES 1164\n",
      "EEKK/ekorpus/105.wav\n",
      "\n",
      "AESDD FILES 605\n",
      "Acted Emotional Speech Dynamic Database/anger/a01 (1).wav\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/SuperKogito/SER-datasets\n",
    "\n",
    "# SAVEE\n",
    "# English (British)\n",
    "# SAVEE FILES 480\n",
    "# SAVEE/AudioData/DC/a01.wav\n",
    "# 480 British English utterances by 4 males actors.\n",
    "# 7 emotions: anger, disgust, fear, happiness, sadness, surprise and neutral.\n",
    "savee_files = sorted(glob('SAVEE/AudioData/*/*.wav'))\n",
    "print(f'SAVEE FILES {len(savee_files)}')\n",
    "print(savee_files[0])\n",
    "print()\n",
    "\n",
    "# TESS\n",
    "# English\n",
    "# TESS FILES 2800\n",
    "# TESS/OAF_back_angry.wav\n",
    "# 2800 recording by 2 actresses.\n",
    "# 7 emotions: anger, disgust, fear, happiness, pleasant surprise, sadness, and neutral.\n",
    "tess_files = sorted(glob('TESS/*.wav'))\n",
    "print(f'TESS FILES {len(tess_files)}')\n",
    "print(tess_files[0])\n",
    "print()\n",
    "\n",
    "# RAVDESS\n",
    "# English\n",
    "# 7356 recordings by 24 actors.\n",
    "# Speech file (Audio_Speech_Actors_01-24.zip, 215 MB) contains 1440 files: \n",
    "# 60 trials per actor x 24 actors = 1440.\n",
    "# Song file (Audio_Song_Actors_01-24.zip, 198 MB) contains 1012 files: \n",
    "# 44 trials per actor x 23 actors = 1012.\n",
    "# RAVDESS FILES 1440\n",
    "# RAVDESS/Actor_01/03-01-01-01-01-01-01.wav\n",
    "# 7 emotions: calm, happy, sad, angry, fearful, surprise, and disgust\n",
    "ravdess_files = sorted(glob('RAVDESS/*/*.wav'))\n",
    "print(f'RAVDESS FILES {len(ravdess_files)}')\n",
    "print(ravdess_files[0])\n",
    "print()\n",
    "\n",
    "# CREMA-D\n",
    "# English\n",
    "# 7442 clip of 12 sentences spoken by 91 actors (48 males and 43 females).\n",
    "# CREAMA-D FILES 7442\n",
    "# CREMA-D/AudioWAV/1001_DFA_ANG_XX.wav\n",
    "# 6 emotions: angry, disgusted, fearful, happy, neutral, and sad\n",
    "crema_d_files = sorted(glob('CREMA-D/AudioWAV/*.wav'))\n",
    "print(f'CREAMA-D FILES {len(crema_d_files)}')\n",
    "print(crema_d_files[0])\n",
    "print()\n",
    "\n",
    "# URDU\n",
    "# Urdu\n",
    "# 400 utterances by 38 speakers (27 male and 11 female).\n",
    "# URDU FILES 400\n",
    "# URDU-Dataset/Angry/SM1_F10_A010.wav\n",
    "# 4 emotions: angry, happy, neutral, and sad.\n",
    "urdu_files = sorted(glob('URDU-Dataset/*/*.wav'))\n",
    "print(f'URDU FILES {len(urdu_files)}')\n",
    "print(urdu_files[0])\n",
    "print()\n",
    "\n",
    "# BAVED\n",
    "# Arabic\n",
    "# 1935 recording by 61 speakers (45 male and 16 female).\n",
    "# BAVED FILES 1935\n",
    "# BAVED/0/0-m-21-0-1-105.wav\n",
    "baved_files = sorted(glob('BAVED/*/*.wav'))\n",
    "print(f'BAVED FILES {len(baved_files)}')\n",
    "print(baved_files[0])\n",
    "print()\n",
    "\n",
    "# VIVAE\n",
    "# non-speech, 1085 audio file by ~12 speakers.\n",
    "# VIVAE FILES 1085\n",
    "# VIVAE/full_set/S01_achievement_low_01.wav\n",
    "# non-speech 6 emotions: achievement, anger, fear, pain, pleasure, and surprise \n",
    "# with 3 emotional intensities (low, moderate, strong, peak).\n",
    "vivae_files = sorted(glob('VIVAE/full_set/*.wav'))\n",
    "print(f'VIVAE FILES {len(vivae_files)}')\n",
    "print(vivae_files[0])\n",
    "print()\n",
    "\n",
    "# ShEMO\n",
    "# 3000 semi-natural utterances, equivalent to 3 hours and 25 minutes \n",
    "# of speech data from online radio plays by 87 native-Persian speakers.\n",
    "# ShEMO FILES 3000\n",
    "# ShEMO/female/F01A01.wav\n",
    "# 6 emotions: anger, fear, happiness, sadness, neutral and surprise.\n",
    "shemo_files = sorted(glob('ShEMO/*/*.wav'))\n",
    "print(f'ShEMO FILES {len(shemo_files)}')\n",
    "print(shemo_files[0])\n",
    "print()\n",
    "\n",
    "# JL corpus\n",
    "# 2400 recording of 240 sentences by 4 actors (2 males and 2 females).\n",
    "# JL corpus FILES 2400\n",
    "# ShEMO/female/F01A01.wav\n",
    "# 5 primary emotions: angry, sad, neutral, happy, excited. \n",
    "# 5 secondary emotions: anxious, apologetic, pensive, worried, enthusiastic.\n",
    "jl_corpus_files = sorted(glob('JL corpus/Raw JL corpus (unchecked and unannotated)/JL(wav+txt)/*.wav'))\n",
    "print(f'JL corpus FILES {len(jl_corpus_files)}')\n",
    "print(shemo_files[0])\n",
    "print()\n",
    "\n",
    "# CaFE\n",
    "# French (Canadian)\n",
    "# 6 different sentences by 12 speakers (6 fmelaes + 6 males).\n",
    "# 12 * 6 * (6 * 2 + 1) \n",
    "# CaFE FILES 936\n",
    "# CaFE_48k/ColŠre/Faible/01-C-1-1.wav\n",
    "# 7 emotions: happy, sad, angry, fearful, surprise, disgust and neutral. \n",
    "# Each emotion is acted in 2 different intensities.\n",
    "cafe_files = sorted(glob('CaFE_48k/*/*/*.wav') + glob('CaFE_48k/*/*.wav'))\n",
    "print(f'CaFE FILES {len(cafe_files)}')\n",
    "print(cafe_files[0])\n",
    "print()\n",
    "\n",
    "# ANAD\n",
    "# Arabic\n",
    "# 1384 recording by multiple speakers.\n",
    "# ANAD FILES 1420\n",
    "# ANAD/1sec_segmented_part1/1sec_segmented_part1/V1_1 (1).wav\n",
    "# 3 emotions: angry, happy, surprised.\n",
    "anad_files = sorted(glob('ANAD/*/*/*.wav'))\n",
    "print(f'ANAD FILES {len(anad_files)}')\n",
    "print(anad_files[0])\n",
    "print()\n",
    "\n",
    "# EEKK\n",
    "# Estonian\n",
    "# 26 text passage read by 10 speakers.\n",
    "# EEKK FILES 1164\n",
    "# EEKK/ekorpus/105.wav\n",
    "# 4 main emotions: joy, sadness, anger and neutral.\n",
    "eekk_files = sorted(glob('EEKK/ekorpus/*.wav'))\n",
    "print(f'EEKK FILES {len(eekk_files)}')\n",
    "print(eekk_files[0])\n",
    "print()\n",
    "\n",
    "# AESDD\n",
    "# Greek\n",
    "# around 500 utterances by a diverse group of actors (over 5 actors) simlating various emotions.\n",
    "# AESDD FILES 605\n",
    "# Acted Emotional Speech Dynamic Database/anger/a01 (1).wav\n",
    "# 5 emotions: anger, disgust, fear, happiness, and sadness.\n",
    "aesdd_files = sorted(glob('Acted Emotional Speech Dynamic Database/*/*.wav'))\n",
    "print(f'AESDD FILES {len(aesdd_files)}')\n",
    "print(aesdd_files[0])\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMODB\n",
    "IEMCAO\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
